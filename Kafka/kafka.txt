
* AMQP(Advanced Message Queing Protocol
- 실제 MQ 제품들 : Erlang, RabbitMQ (java based)
- 기존 MQ는 이기종 간의 메세지 format conversion을 할 때 메세지브릿지를 이용, 또는 시스템 통일의 불편함과 비효율성

* Kafka의 토픽은 AMQP와는 다르게 동작
- 토픽은 데이터베이스의 테이블이나 파일시스템의 폴더와 유사한 성질
- 프로듀서가 데이터를 넣고, 컨슈머는 데이터를 가져간다
- 토픽은 이름을 가진다. 목적에 따라 클릭로그, send sms, location log 등 무슨 데이터를 담는 지
  명확히 기재하면 추후 유지보수시 편리하게 관리 가능
- 하나의 토픽은 여러개의 파티션으로 구성
- 하나의 파티션은 Queue와 같이 파티션 끝에서부터 차곡차곡 쌓임

** 컨슈머가 토픽 내부의 파티션에서 데이터(레코드)를 가져가더라도 데이터는 삭제되지 않음
** 새로운 컨슈머가 붙으면 0부터 가져가서 사용가능. 다만, 컨슈머 그룹이 달라야하고,
   auto.offset.reset=earliest로 설정
- 이는 동일 데이터를 2번 사용할 수 있는데, Kafka를 사용하는 아주 중요한 이유.

- 프로듀서가 데이터를 보낼 때, key를 지정해서 파티션을 선택가능
** 만약, 키가 null. (즉, 키를 지정하지 않고 기본 파티셔너 설정을 사용) -> round-robin으로 파티션 지정
*** round-robin(RR) : 프로세스가 도착한 순서대로 프로세스를 디스패치. 정해진 시간 할당량에(또는 시간 간격에)에 의해 실행 제한
** 만약, 키가 있고, 기본파티셔너를 사용할 경우에는 키의 해시값을 구하고, 특정 파티션에 항상 할당

- 파티션을 늘릴 수는 있지만, 다시 줄일 수는 없다
** 파티션을 늘리면, 컨슈머 개수를 늘려서 데이터 처리를 분산시킬 수 있다.

- 파티션의 데이터 삭제는 옵션에 따라 다르다.
** 레코드가 저장되는 최대 시간과 크기를 지정 가능
** log.retention.ms : 최대 보존 시간 / log.retension.byte : 최대 보존 크기 (byte)


* Before Kafka
- 엔드투엔드(end-to-end)연결 방식의 아키텍쳐
- 데이터 연동의 복잡성 증가(하드웨어, 운영체제, 장애 등)
- 각기 다른 데이터 파이프라인 연결 구조
- 확장에 엄청난 노력 필요
☆ 모든 시스템으로 데이터를 전송 시시간 처리도 가능한 것. 데이터가 갑자기 많아지더라도 확장이 용이한 시스템이 필요함 ☆
- 링크드인 자체 데이터 관련 팀에서 개발하여 만들게 됨

* After Kafka
- 프로듀서/컨슈머 분리
- 메세지 데이터를 여러 컨슈머에게 허용
- 높은 처리량을 위한 메세지 최ㅓㅈㄱ화
- 스케일 아웃 가능한 ☆
- 관련 생태계 제공

* Kafka broker & Cluster
* Kafka brroker
- 실행된 카프카 애플리케이션 서버 중 1대
- 3대 이상의 브로커로 클러스터 구성
- 주키퍼와 연동(~2.5.0 버전)
	- 주키퍼의 역할 : 메타데이터(브러커id, 컨트롤럴id 등) 저장
- n개의 브로커 중 1대는 컨트롤러(Controller)기능 수행
	- 컨트롤러 : 각 브로커에게 담당 파티션 할당 수행. 브로커 정상 동작 모니터링 관리. 누가 컨트롤러 인지는 주키퍼에 저장.
	

* Record

new ProducerRecord<String, String>("topic", "key", "message")

new ConsumerRecord<String, String> records = consumer.poll(1000);
for (ConsumerRecord<String, String> record : records) {
	...
}

- 객체를 프로듀서에서 컨슈머로 전달하기 위해 Kafka 내부에 byte 형태로 저장할 수 있도록 직렬화/역직렬화하여 사용가능
- 기본 제공 직렬화 class : StringSerializer, ShortSerializer 등
- 커스텀 직렬화 class를 통해 Custom Object 직렬화/역직렬화 가능
** Producer와 Consumer의 직렬화/역직렬화 객체는 동일하게 맞추어야 한다.

* Topic & Partition
** Topic의 Partition은 한 개 이상이 반드시 존재

- 메세지 분류 단위
- n개의 파티션 할당 가능
- 각 파티션마다 고유한 오프셋(offset)을 가짐.
- 메세지 처리 순서는 파티션 별로 유지 관리됨

* Producer & Consumer
1. 프로듀서는 레코드를 생성하여 브로커로 전송
2. 전송된 레코드는 파티션에 신규 오프셋과 함께 기록됨
3. 컨슈머는 브로커로부터 레코드를 요청하여 가져감 (polling)
** 절대로 브로커가 컨슈머로 레코드를 보내는 게 아님을 참고

* Kafka log and segment
** segment file : ["~.index", "~.log", "~.timeindex"]
- 실제로 메세지가 저장되는 파일시스템 단위
- 메세지가 저장될 때는 세그먼트 파일이 열려있음 
- 세그먼트는 시간 또는 크기 기준으로 닫힘
- 세그먼트가 닫힌 이후 일정 시간(또는 용량)에 따라 삭제(delete) 또는 압축(compact) 